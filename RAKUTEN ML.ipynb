{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ca4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d857ec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \n",
       "0                                                NaN  3804725264  1263597046  \n",
       "1                                                NaN   436067568  1008141237  \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978  \n",
       "3                                                NaN    50418756   457047496  \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"X.csv\", index_col = 0)\n",
    "df = df_original\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ca81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_junction(column1,column2):\n",
    "    if str(column2).lower() ==\"nan\":\n",
    "        return str(column1)\n",
    "    else:\n",
    "        return str(column1) + \" \" + str(column2)\n",
    "\n",
    "df[\"text\"] = df.apply(lambda x : column_junction(x[\"designation\"],x[\"description\"]),axis=1)\n",
    "#df[\"text\"] = df.apply(lambda x : str(x[\"designation\"]) + \" \" + str(x[\"description\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c2e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]= df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8105a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ac7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    output= \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    return output\n",
    "#applying the function\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59cb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('french')\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c7da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>journal arts n° 133 28092001 lart marche salon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>guerre tuques luc ideacutees grandeur veut org...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \\\n",
       "0                                                NaN  3804725264  1263597046   \n",
       "1                                                NaN   436067568  1008141237   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
       "3                                                NaN    50418756   457047496   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
       "\n",
       "                                                text  \n",
       "0  olivia personalisiertes notizbuch 150 seiten p...  \n",
       "1  journal arts n° 133 28092001 lart marche salon...  \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...  \n",
       "3  peluche donald europe disneyland 2000 marionne...  \n",
       "4  guerre tuques luc ideacutees grandeur veut org...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c42ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "df[\"text\"] = df[\"text\"].apply(lambda text: stem_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8dcadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df= 50)\n",
    "vectorizer.fit_transform(df[\"text\"])\n",
    "tokenized = vectorizer.vocabulary_\n",
    "X = vectorizer.transform(df[\"text\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f841e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 7130)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4afe4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = pd.read_csv(\"Y.csv\", index_col = 0)\n",
    "y[\"prdtypecode\"] = le.fit_transform(y[\"prdtypecode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5fc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = y[\"prdtypecode\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7377281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b074b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5abc254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                213930    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                837       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 214,767\n",
      "Trainable params: 214,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "6369/6369 [==============================] - 182s 29ms/step - loss: 1.1035 - accuracy: 0.7111 - val_loss: 0.8258 - val_accuracy: 0.7670\n",
      "Epoch 2/10\n",
      "6369/6369 [==============================] - 149s 23ms/step - loss: 0.6157 - accuracy: 0.8186 - val_loss: 0.7927 - val_accuracy: 0.7788\n",
      "Epoch 3/10\n",
      "6369/6369 [==============================] - 165s 26ms/step - loss: 0.4713 - accuracy: 0.8570 - val_loss: 0.8475 - val_accuracy: 0.7788\n",
      "Epoch 4/10\n",
      "6369/6369 [==============================] - 166s 26ms/step - loss: 0.3874 - accuracy: 0.8796 - val_loss: 0.9117 - val_accuracy: 0.7755\n",
      "Epoch 5/10\n",
      "6369/6369 [==============================] - 163s 26ms/step - loss: 0.3299 - accuracy: 0.8972 - val_loss: 1.0158 - val_accuracy: 0.7721\n",
      "Epoch 6/10\n",
      "6369/6369 [==============================] - 169s 27ms/step - loss: 0.2907 - accuracy: 0.9097 - val_loss: 1.0897 - val_accuracy: 0.7710\n",
      "Epoch 7/10\n",
      "6369/6369 [==============================] - 170s 27ms/step - loss: 0.2579 - accuracy: 0.9208 - val_loss: 1.1830 - val_accuracy: 0.7672\n",
      "Epoch 8/10\n",
      "6369/6369 [==============================] - 233s 37ms/step - loss: 0.2348 - accuracy: 0.9278 - val_loss: 1.2807 - val_accuracy: 0.7658\n",
      "Epoch 9/10\n",
      "6369/6369 [==============================] - 237s 37ms/step - loss: 0.2134 - accuracy: 0.9350 - val_loss: 1.3453 - val_accuracy: 0.7639\n",
      "Epoch 10/10\n",
      "6369/6369 [==============================] - 185s 29ms/step - loss: 0.1956 - accuracy: 0.9396 - val_loss: 1.4529 - val_accuracy: 0.7619\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , Dropout ,MaxPooling2D,Flatten, Dense, Input, Reshape, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_dim = X_train.shape[1] \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (input_dim ), name = \"Input\"))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2859556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Rakuten_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Rakuten_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "#from tensorflow.keras.saving import save_model\n",
    "\n",
    "CV_filename = \"Rakuten_CountVectorizer.sav\"\n",
    "joblib.dump(vectorizer, CV_filename)\n",
    "LE_filename = \"Rakuten_LabelEncoder.sav\"\n",
    "joblib.dump(le, LE_filename)\n",
    "model_filename = 'Rakuten_model.sav'\n",
    "#tf.keras.saving.save_model(\n",
    "#    model, 'C:/Users/Dan/Documents/GitHub\\Rakuten', overwrite=True)\n",
    "#model.save('C:/Users/Dan/Documents/GitHub/Rakuten')\n",
    "model.save('Rakuten_model')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afada198",
   "metadata": {},
   "source": [
    "#Input()\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n",
    "                padding=\"valid\",\n",
    "                input_shape=(100, 100, 3)))\n",
    "model.add(Embedding)\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf3e92db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[1140]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def text_processing(title,desc):\n",
    "    text = str(title) + \" \" + str(desc)\n",
    "    text = text.lower()\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    stopword = stopwords.words('english')\n",
    "    text = \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    stopword = stopwords.words('french')\n",
    "    text = \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    stemmer = SnowballStemmer(\"french\")\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    vectorizer = joblib.load(\"Rakuten_CountVectorizer.sav\")\n",
    "    X = vectorizer.transform([text]).todense()\n",
    "    return X\n",
    "\n",
    "title = \"Super jouet de folie\"\n",
    "desc = \"une figurine qui fera rever les enfants\"\n",
    "\n",
    "def prediction(X):\n",
    "    model = load_model('Rakuten_model')\n",
    "    proba = np.max(model.predict(X)) \n",
    "    pred_class = np.argmax(model.predict(X), axis=-1) \n",
    "    le = joblib.load(\"Rakuten_LabelEncoder.sav\")\n",
    "    classe = le.inverse_transform(pred_class)\n",
    "    return (classe, proba)\n",
    "\n",
    "\n",
    "\n",
    "X = prediction(text_processing(title,desc))\n",
    "print(X[0])\n",
    "print(round(X[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
