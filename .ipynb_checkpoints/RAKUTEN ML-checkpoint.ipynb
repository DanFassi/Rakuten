{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ca4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d857ec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \n",
       "0                                                NaN  3804725264  1263597046  \n",
       "1                                                NaN   436067568  1008141237  \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978  \n",
       "3                                                NaN    50418756   457047496  \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"X.csv\", index_col = 0)\n",
    "df = df_original\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ca81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_junction(column1,column2):\n",
    "    if str(column2).lower() ==\"nan\":\n",
    "        return str(column1)\n",
    "    else:\n",
    "        return str(column1) + \" \" + str(column2)\n",
    "\n",
    "df[\"text\"] = df.apply(lambda x : column_junction(x[\"designation\"],x[\"description\"]),axis=1)\n",
    "#df[\"text\"] = df.apply(lambda x : str(x[\"designation\"]) + \" \" + str(x[\"description\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c2e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]= df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8105a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ac7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    output= \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    return output\n",
    "#applying the function\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59cb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('french')\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c7da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>journal arts n° 133 28092001 lart marche salon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>guerre tuques luc ideacutees grandeur veut org...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \\\n",
       "0                                                NaN  3804725264  1263597046   \n",
       "1                                                NaN   436067568  1008141237   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
       "3                                                NaN    50418756   457047496   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
       "\n",
       "                                                text  \n",
       "0  olivia personalisiertes notizbuch 150 seiten p...  \n",
       "1  journal arts n° 133 28092001 lart marche salon...  \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...  \n",
       "3  peluche donald europe disneyland 2000 marionne...  \n",
       "4  guerre tuques luc ideacutees grandeur veut org...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c42ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "df[\"text\"] = df[\"text\"].apply(lambda text: stem_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dcadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df= 50)\n",
    "vectorizer.fit_transform(df[\"text\"])\n",
    "tokenized = vectorizer.vocabulary_\n",
    "X = vectorizer.transform(df[\"text\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59f841e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 7103)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4afe4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = pd.read_csv(\"Y.csv\", index_col = 0)\n",
    "y[\"prdtypecode\"] = le.fit_transform(y[\"prdtypecode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d5fc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = y[\"prdtypecode\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7377281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b074b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5abc254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 30)                213120    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 27)                837       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,957\n",
      "Trainable params: 213,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "6369/6369 [==============================] - 186s 29ms/step - loss: 1.0920 - accuracy: 0.7142 - val_loss: 0.8192 - val_accuracy: 0.7677\n",
      "Epoch 2/10\n",
      "6369/6369 [==============================] - 160s 25ms/step - loss: 0.6075 - accuracy: 0.8188 - val_loss: 0.7853 - val_accuracy: 0.7785\n",
      "Epoch 3/10\n",
      "6369/6369 [==============================] - 155s 24ms/step - loss: 0.4667 - accuracy: 0.8570 - val_loss: 0.8314 - val_accuracy: 0.7785\n",
      "Epoch 4/10\n",
      "6369/6369 [==============================] - 149s 23ms/step - loss: 0.3831 - accuracy: 0.8807 - val_loss: 0.9087 - val_accuracy: 0.7761\n",
      "Epoch 5/10\n",
      "6369/6369 [==============================] - 151s 24ms/step - loss: 0.3309 - accuracy: 0.8965 - val_loss: 0.9770 - val_accuracy: 0.7729\n",
      "Epoch 6/10\n",
      "6369/6369 [==============================] - 158s 25ms/step - loss: 0.2900 - accuracy: 0.9092 - val_loss: 1.0692 - val_accuracy: 0.7719\n",
      "Epoch 7/10\n",
      "6369/6369 [==============================] - 140s 22ms/step - loss: 0.2605 - accuracy: 0.9189 - val_loss: 1.1524 - val_accuracy: 0.7682\n",
      "Epoch 8/10\n",
      "6369/6369 [==============================] - 152s 24ms/step - loss: 0.2349 - accuracy: 0.9267 - val_loss: 1.2451 - val_accuracy: 0.7688\n",
      "Epoch 9/10\n",
      "6369/6369 [==============================] - 146s 23ms/step - loss: 0.2167 - accuracy: 0.9334 - val_loss: 1.3207 - val_accuracy: 0.7640\n",
      "Epoch 10/10\n",
      "6369/6369 [==============================] - 152s 24ms/step - loss: 0.2000 - accuracy: 0.9379 - val_loss: 1.4137 - val_accuracy: 0.7639\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , Dropout ,MaxPooling2D,Flatten, Dense, Input, Reshape, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_dim = X_train.shape[1] \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (input_dim ), name = \"Input\"))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2859556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rakuten_model.sav']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "CV_filename = \"Rakuten_CountVectorizer.sav\"\n",
    "joblib.dump(vectorizer, CV_filename)\n",
    "LE_filename = \"Rakuten_LabelEncoder.sav\"\n",
    "joblib.dump(le, LE_filename)\n",
    "model_filename = 'Rakuten_model.sav'\n",
    "joblib.dump(model, model_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afada198",
   "metadata": {},
   "source": [
    "#Input()\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n",
    "                padding=\"valid\",\n",
    "                input_shape=(100, 100, 3)))\n",
    "model.add(Embedding)\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation=\"linear\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
