{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ca4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d857ec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...  \n",
       "3                                                NaN  \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"X.csv\")\n",
    "df = df_original\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ca81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_junction(column1,column2):\n",
    "    if str(column2).lower() ==\"nan\":\n",
    "        return str(column1)\n",
    "    else:\n",
    "        return str(column1) + \" \" + str(column2)\n",
    "\n",
    "df[\"text\"] = df.apply(lambda x : column_junction(x[\"designation\"],x[\"description\"]),axis=1)\n",
    "#df[\"text\"] = df.apply(lambda x : str(x[\"designation\"]) + \" \" + str(x[\"description\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c2e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]= df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8105a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ac7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    output= \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    return output\n",
    "#applying the function\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59cb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('french')\n",
    "df[\"text\"]= df[\"text\"].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c7da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>journal arts n° 133 28092001 lart marche salon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>guerre tuques luc ideacutees grandeur veut org...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   \n",
       "3                                                NaN   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   \n",
       "\n",
       "                                                text  \n",
       "0  olivia personalisiertes notizbuch 150 seiten p...  \n",
       "1  journal arts n° 133 28092001 lart marche salon...  \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...  \n",
       "3  peluche donald europe disneyland 2000 marionne...  \n",
       "4  guerre tuques luc ideacutees grandeur veut org...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c42ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "df[\"text\"] = df[\"text\"].apply(lambda text: stem_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8dcadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df= 50)\n",
    "vectorizer.fit_transform(df[\"text\"])\n",
    "tokenized = vectorizer.vocabulary_\n",
    "X = vectorizer.transform(df[\"text\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f841e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 7130)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4afe4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = pd.read_csv(\"Y.csv\", index_col = 0)\n",
    "y[\"prdtypecode\"] = le.fit_transform(y[\"prdtypecode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5fc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = y[\"prdtypecode\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7377281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b074b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5abc254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                213930    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                837       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 214,767\n",
      "Trainable params: 214,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "6369/6369 [==============================] - 163s 26ms/step - loss: 1.0937 - accuracy: 0.7127 - val_loss: 0.8080 - val_accuracy: 0.7701\n",
      "Epoch 2/10\n",
      "6369/6369 [==============================] - 181s 28ms/step - loss: 0.6009 - accuracy: 0.8202 - val_loss: 0.7805 - val_accuracy: 0.7797\n",
      "Epoch 3/10\n",
      "6369/6369 [==============================] - 172s 27ms/step - loss: 0.4589 - accuracy: 0.8590 - val_loss: 0.8359 - val_accuracy: 0.7787\n",
      "Epoch 4/10\n",
      "6369/6369 [==============================] - 178s 28ms/step - loss: 0.3779 - accuracy: 0.8822 - val_loss: 0.9177 - val_accuracy: 0.7750\n",
      "Epoch 5/10\n",
      "6369/6369 [==============================] - 195s 31ms/step - loss: 0.3253 - accuracy: 0.8986 - val_loss: 0.9806 - val_accuracy: 0.7730\n",
      "Epoch 6/10\n",
      "6369/6369 [==============================] - 182s 29ms/step - loss: 0.2841 - accuracy: 0.9112 - val_loss: 1.0660 - val_accuracy: 0.7734\n",
      "Epoch 7/10\n",
      "6369/6369 [==============================] - 164s 26ms/step - loss: 0.2544 - accuracy: 0.9213 - val_loss: 1.1587 - val_accuracy: 0.7719\n",
      "Epoch 8/10\n",
      "6369/6369 [==============================] - 157s 25ms/step - loss: 0.2295 - accuracy: 0.9280 - val_loss: 1.2610 - val_accuracy: 0.7668\n",
      "Epoch 9/10\n",
      "6369/6369 [==============================] - 164s 26ms/step - loss: 0.2118 - accuracy: 0.9341 - val_loss: 1.3258 - val_accuracy: 0.7621\n",
      "Epoch 10/10\n",
      "6369/6369 [==============================] - 166s 26ms/step - loss: 0.1950 - accuracy: 0.9389 - val_loss: 1.4284 - val_accuracy: 0.7661\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , Dropout ,MaxPooling2D,Flatten, Dense, Input, Reshape, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_dim = X_train.shape[1] \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (input_dim ), name = \"Input\"))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2859556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Rakuten_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Rakuten_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "#from tensorflow.keras.saving import save_model\n",
    "\n",
    "CV_filename = \"Rakuten_CountVectorizer.sav\"\n",
    "joblib.dump(vectorizer, CV_filename)\n",
    "LE_filename = \"Rakuten_LabelEncoder.sav\"\n",
    "joblib.dump(le, LE_filename)\n",
    "model_filename = 'Rakuten_model.sav'\n",
    "#tf.keras.saving.save_model(\n",
    "#    model, 'C:/Users/Dan/Documents/GitHub\\Rakuten', overwrite=True)\n",
    "#model.save('C:/Users/Dan/Documents/GitHub/Rakuten')\n",
    "model.save('Rakuten_model')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afada198",
   "metadata": {},
   "source": [
    "#Input()\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n",
    "                padding=\"valid\",\n",
    "                input_shape=(100, 100, 3)))\n",
    "model.add(Embedding)\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf3e92db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[1140]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def text_processing(title,desc):\n",
    "    text = str(title) + \" \" + str(desc)\n",
    "    text = text.lower()\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    stopword = stopwords.words('english')\n",
    "    text = \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    stopword = stopwords.words('french')\n",
    "    text = \" \".join([word for word in str(text).split() if word not in stopword])\n",
    "    stemmer = SnowballStemmer(\"french\")\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    vectorizer = joblib.load(\"Rakuten_CountVectorizer.sav\")\n",
    "    X = vectorizer.transform([text]).todense()\n",
    "    return X\n",
    "\n",
    "title = \"Super jouet de folie\"\n",
    "desc = \"une figurine qui fera rever les enfants\"\n",
    "\n",
    "def prediction(X):\n",
    "    model = load_model('Rakuten_model')\n",
    "    proba = np.max(model.predict(X)) \n",
    "    pred_class = np.argmax(model.predict(X), axis=-1) \n",
    "    le = joblib.load(\"Rakuten_LabelEncoder.sav\")\n",
    "    classe = le.inverse_transform(pred_class)\n",
    "    return (classe, proba)\n",
    "\n",
    "\n",
    "\n",
    "X = prediction(text_processing(title,desc))\n",
    "print(X[0])\n",
    "print(round(X[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
